[tool:pytest]
# Test discovery and execution configuration
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test* *Tests
python_functions = test_*

# Test execution options
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov=src
    --cov-report=term-missing
    --cov-report=html:tests/reports/coverage
    --cov-report=xml:tests/reports/coverage.xml
    --cov-fail-under=80
    --html=tests/reports/pytest_report.html
    --self-contained-html
    --junitxml=tests/reports/junit.xml
    --disable-warnings

# Async test configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = session

# Test markers for categorization
markers =
    unit: Unit tests that test individual components in isolation
    integration: Integration tests that test multiple components together
    api: API endpoint tests
    database: Database-related tests
    rag: RAG system and AI-related tests
    ui: User interface tests
    performance: Performance and benchmark tests
    security: Security-related tests
    slow: Tests that take more than 5 seconds to run
    fast: Tests that run in under 1 second
    requires_openai: Tests that require OpenAI API access
    requires_github: Tests that require GitHub API access
    requires_network: Tests that require internet connectivity
    bug_fix: Tests that verify bug fixes
    regression: Tests that prevent regressions
    edge_cases: Tests that cover edge cases
    backward_compatibility: Tests that ensure backward compatibility
    websocket: Tests that cover websocket functionality

# Test collection configuration
minversion = 7.0
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:chromadb
    ignore::UserWarning:flet

# Logging configuration for tests
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test timeout (in seconds)
timeout = 300
timeout_method = thread